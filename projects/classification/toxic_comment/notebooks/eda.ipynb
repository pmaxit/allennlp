{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a432a6-c1ad-42bc-9304-71be43124bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48aba827-6152-409a-b882-981f8e366e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data import DataLoader\n",
    "from allennlp.data.samplers import BucketBatchSampler\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
    "from allennlp.common.util import ensure_list\n",
    "\n",
    "from allennlp_models.classification.dataset_readers.stanford_sentiment_tree_bank import \\\n",
    "    StanfordSentimentTreeBankDatasetReader\n",
    "from allennlp.data.data_loaders import SimpleDataLoader\n",
    "from allennlp.training import GradientDescentTrainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5149d4-196b-4c5e-a89f-07f3ebd3f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25be2ec2-793e-4967-b17e-281091cacee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model in AllenNLP represents a model that is trained.\n",
    "@Model.register(\"lstm_classifier\")\n",
    "class LstmClassifier(Model):\n",
    "    def __init__(self,\n",
    "                 embedder: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 vocab: Vocabulary,\n",
    "                 positive_label: str = '4') -> None:\n",
    "        super().__init__(vocab)\n",
    "        # We need the embeddings to convert word IDs to their vector representations\n",
    "        self.embedder = embedder\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # After converting a sequence of vectors to a single vector, we feed it into\n",
    "        # a fully-connected linear layer to reduce the dimension to the total number of labels.\n",
    "        self.linear = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
    "                                      out_features=vocab.get_vocab_size('labels'))\n",
    "\n",
    "        # Monitor the metrics - we use accuracy, as well as prec, rec, f1 for 4 (very positive)\n",
    "        positive_index = vocab.get_token_index(positive_label, namespace='labels')\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        self.f1_measure = F1Measure(positive_index)\n",
    "\n",
    "        # We use the cross entropy loss because this is a classification task.\n",
    "        # Note that PyTorch's CrossEntropyLoss combines softmax and log likelihood loss,\n",
    "        # which makes it unnecessary to add a separate softmax layer.\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Instances are fed to forward after batching.\n",
    "    # Fields are passed through arguments with the same name.\n",
    "    def forward(self,\n",
    "                tokens: Dict[str, torch.Tensor],\n",
    "                label: torch.Tensor = None) -> torch.Tensor:\n",
    "        # In deep NLP, when sequences of tensors in different lengths are batched together,\n",
    "        # shorter sequences get padded with zeros to make them equal length.\n",
    "        # Masking is the process to ignore extra zeros added by padding\n",
    "        mask = get_text_field_mask(tokens)\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings = self.embedder(tokens)\n",
    "        encoder_out = self.encoder(embeddings, mask)\n",
    "        logits = self.linear(encoder_out)\n",
    "\n",
    "        # In AllenNLP, the output of forward() is a dictionary.\n",
    "        # Your output dictionary must contain a \"loss\" key for your model to be trained.\n",
    "        output = {\"logits\": logits}\n",
    "        if label is not None:\n",
    "            self.accuracy(logits, label)\n",
    "            self.f1_measure(logits, label)\n",
    "            output[\"loss\"] = self.loss_function(logits, label)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        precision, recall, f1_measure = self.f1_measure.get_metric(reset)\n",
    "        return {'accuracy': self.accuracy.get_metric(reset),\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_measure': f1_measure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937bdcc6-40ea-48bd-a8c1-816a854f626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = StanfordSentimentTreeBankDatasetReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ccbf30-3241-4760-aeaf-1eb6b6835c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/train.txt')\n",
    "dev_dataset = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05c827f-7bfb-4143-8c5d-1c844b8f5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=ensure_list(train_dataset)\n",
    "dev_dataset=ensure_list(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b36feb-18c4-4d44-8296-f4ebc6c0acd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2443cef06b234fbb858495f51a0cc952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab:   0%|          | 0/9645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can optionally specify the minimum count of tokens/labels.\n",
    "# `min_count={'tokens':3}` here means that any tokens that appear less than three times\n",
    "# will be ignored and not included in the vocabulary.\n",
    "vocab = Vocabulary.from_instances(instances=train_dataset+dev_dataset,\n",
    "                                  min_count={'tokens': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2dab8cb-b59c-4f7f-96c7-c237bb7d6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = SimpleDataLoader(train_dataset, batch_size=32)\n",
    "dev_data_loader = SimpleDataLoader(dev_dataset, batch_size=32)\n",
    "\n",
    "train_data_loader.index_with(vocab)\n",
    "dev_data_loader.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba66e901-6fe2-48bf-a090-e4190e607086",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "307c4206-caf7-460b-8a7c-30daa3decb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BasicTextFieldEmbedder takes a dict - we need an embedding just for tokens,\n",
    "# not for labels, which are used as-is as the \"answer\" of the sentence classification\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding}).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12cc0fcc-7075-4c18-ba7c-f57fb792e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2VecEncoder is a neural network abstraction that takes a sequence of something\n",
    "# (usually a sequence of embedded word vectors), processes it, and returns a single\n",
    "# vector. Oftentimes this is an RNN-based architecture (e.g., LSTM or GRU), but\n",
    "# AllenNLP also supports CNNs and other simple architectures (for example,\n",
    "# just averaging over the input vectors).\n",
    "encoder = PytorchSeq2VecWrapper(\n",
    "    torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a78df1f-53fe-4c51-bc4d-e79424dfbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmClassifier(word_embeddings, encoder, vocab).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f432f0a-129d-4ba4-9825-30cbf598237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b895e8-afe1-4fd7-a215-4c1533486340",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GradientDescentTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_data_loader,\n",
    "    num_epochs=10,\n",
    "    gpus=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c8163c-7c13-4f99-bcca-9c1afb7b7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.commands.find_learning_rate import *\n",
    "\n",
    "def _smooth(values: List[float], beta: float) -> List[float]:\n",
    "    \"\"\" Exponential smoothing of values \"\"\"\n",
    "    avg_value = 0.0\n",
    "    smoothed = []\n",
    "    for i, value in enumerate(values):\n",
    "        avg_value = beta * avg_value + (1 - beta) * value\n",
    "        smoothed.append(avg_value / (1 - beta ** (i + 1)))\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d27b5146-9da9-4016-ba00-91d4a6f950d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c9358de66848829d18d13cbcac03e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2744398ca0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learning_rates, losses = search_learning_rate(trainer,end_lr=1.0)\n",
    "losses = _smooth(losses, 0.98)\n",
    "plt.plot(learning_rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8a5bfe5-dbd7-45a5-84ad-4d8f755e379f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9498effde524744b8885e75de8ca049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/venv/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36m_try_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs_completed\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_after_epochs_completed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;31m# Updating tqdm only for the primary as the trainers wouldn't have one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription_from_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m                 \u001b[0mbatch_group_generator_tqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.8/site-packages/allennlp/training/util.py\u001b[0m in \u001b[0;36mdescription_from_metrics\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m    426\u001b[0m     return (\n\u001b[1;32m    427\u001b[0m         \", \".join(\n\u001b[0;32m--> 428\u001b[0;31m             [\n\u001b[0m\u001b[1;32m    429\u001b[0m                 \u001b[0;34m\"%s: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.8/site-packages/allennlp/training/util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \", \".join(\n\u001b[1;32m    428\u001b[0m             [\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0;34m\"%s: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c84ec43c-5e3a-4756-bcca-0133c79aae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/puneet/Envs/venv/lib/python3.8/site-packages/allennlp/training/util.py\u001b[0m(429)\u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    427 \u001b[0;31m        \", \".join(\n",
      "\u001b[0m\u001b[0;32m    428 \u001b[0;31m            [\n",
      "\u001b[0m\u001b[0;32m--> 429 \u001b[0;31m                \u001b[0;34m\"%s: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    430 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    431 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'precision'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'precision'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7ae20-0844-48dc-ad6a-0b0aebb7e228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
